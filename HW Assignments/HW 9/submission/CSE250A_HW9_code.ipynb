{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78273311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626a3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile(filename, multi_col=False):\n",
    "    contents = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            temp = line.strip('\\n').strip()\n",
    "            if multi_col:\n",
    "                temp = temp.split()\n",
    "            contents.append(temp)\n",
    "    \n",
    "    return np.asarray([np.array(x) for x in contents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "113c1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_a1_df = loadFile('prob_a1.txt', multi_col=True).astype(np.float32)\n",
    "prob_a2_df = loadFile('prob_a2.txt', multi_col=True).astype(np.float32)\n",
    "prob_a3_df = loadFile('prob_a3.txt', multi_col=True).astype(np.float32)\n",
    "prob_a4_df = loadFile('prob_a4.txt', multi_col=True).astype(np.float32)\n",
    "rewards_df = loadFile('rewards.txt').astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4357692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04562342",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.zeros((81, 81, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813b6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_probs = [prob_a1_df, prob_a2_df, prob_a3_df, prob_a4_df]\n",
    "for i in range(len(condensed_probs)):\n",
    "    condensed_prob = condensed_probs[i]\n",
    "    for prob in condensed_prob:\n",
    "        probs[int(prob[0]) - 1][int(prob[1]) - 1][i] = prob[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e1ca9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_states = np.array([3, 11,12,15,16,17,20,22,23,24,26,29,30, 31, 34, 35, 39, 43, 48, 56, 57, 58, 59, 60, 61, 62, 66, 70, 71])\n",
    "valid_states = valid_states - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4139b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcValFunc(policy):\n",
    "    newProbMat = None\n",
    "    for pi in range(policy.shape[0]):\n",
    "        temp = probs[pi, :, policy[pi]]\n",
    "        if newProbMat is None:\n",
    "            newProbMat = temp\n",
    "        else:\n",
    "            newProbMat = np.vstack((newProbMat, temp))\n",
    "    newProbMat = np.identity((newProbMat.shape[0])) - gamma * newProbMat\n",
    "    \n",
    "    return np.matmul(np.linalg.inv(newProbMat), rewards_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e06a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcNewValFunc(valueFunction, policy):\n",
    "    newProbMat = None\n",
    "    for pi in range(policy.shape[0]):\n",
    "        temp = probs[pi, :, policy[pi]]\n",
    "        if newProbMat is None:\n",
    "            newProbMat = temp\n",
    "        else:\n",
    "            newProbMat = np.vstack((newProbMat, temp))\n",
    "    return rewards_df + gamma * np.sum(newProbMat * valueFunction, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa60d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewPolicy(valueFunction, policy):\n",
    "    for pi in range(policy.shape[0]):\n",
    "        max_val = -np.inf\n",
    "        max_action = -np.inf\n",
    "        for action in range(4):\n",
    "            temp = np.sum(probs[pi, :, action] * valueFunction)\n",
    "            if max_val < temp:\n",
    "                max_val = temp\n",
    "                max_action = action\n",
    "        policy[pi] = max_action\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c039c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomPolicy():\n",
    "    policy = np.empty((81,), dtype=np.int32)\n",
    "    for i in range(policy.shape[0]):\n",
    "        policy[i] = random.randint(0, 3)\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25f72e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = getRandomPolicy()\n",
    "valueFunc = calcValFunc(policy)\n",
    "opt_policy = getNewPolicy(valueFunc, policy)\n",
    "newValueFunc = calcNewValFunc(valueFunc, opt_policy)#calcValFunc(opt_policy)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e33d1d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence in 5 steps\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while not np.equal(newValueFunc, valueFunc).all():\n",
    "    i += 1\n",
    "    valueFunc = newValueFunc.copy()\n",
    "    opt_policy = getNewPolicy(valueFunc, opt_policy)\n",
    "    newValueFunc = calcValFunc(opt_policy)\n",
    "print('Convergence in {} steps'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18e78909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    0.        ,  100.7010102 ,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,  102.37529123,  101.52367323,\n",
       "          0.        ,    0.        ,  109.48995052,  110.40904748,\n",
       "        111.33585966,    0.        ,    0.        ,  103.23464898,\n",
       "          0.        ,  106.77828777,  107.67464526,  108.57850454,\n",
       "          0.        ,  112.27045183,    0.        ,    0.        ,\n",
       "        104.10123631,  104.97509851,  105.88855749,    0.        ,\n",
       "          0.        ,  114.16323791,  113.21288929,    0.        ,\n",
       "          0.        ,    0.        ,  103.78143159,    0.        ,\n",
       "          0.        ,    0.        ,  115.12156408,    0.        ,\n",
       "          0.        ,    0.        , -133.33333333,   90.98540322,\n",
       "       -133.33333333,    0.        , -133.33333333,  116.08793478,\n",
       "        122.02491933,    0.        ,    0.        ,   81.39950233,\n",
       "         93.67166485,   95.1728646 ,  108.34262576,  109.58365563,\n",
       "        123.64307385,  123.18224439,    0.        ,    0.        ,\n",
       "       -133.33333333,   81.39950233, -133.33333333,    0.        ,\n",
       "       -133.33333333,  125.24979123,  124.20738921,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,  133.33333333,    0.        ,\n",
       "          0.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueFunc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2907202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valueFuncIteration(valueFunction):\n",
    "    newProbMat = None\n",
    "    for pi in range(policy.shape[0]):\n",
    "        max_val = -np.inf\n",
    "        max_temp = None\n",
    "        for a in range(4):\n",
    "            temp = probs[pi, :, a]\n",
    "            temp_val = np.sum(temp * valueFunction, axis=0)\n",
    "            if max_val < temp_val:\n",
    "                max_val = temp_val\n",
    "                max_temp = temp\n",
    "        if newProbMat is None:\n",
    "            newProbMat = max_temp\n",
    "        else:\n",
    "            newProbMat = np.vstack((newProbMat, max_temp))\n",
    "    return rewards_df + gamma * np.sum(newProbMat * valueFunction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58dc859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = getRandomPolicy()\n",
    "valueFunc2 = np.array([0]*policy.shape[0])\n",
    "tempFunc = valueFuncIteration(valueFunc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17d93d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence in 2304 steps\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while np.sum(np.absolute(valueFunc2 - tempFunc)) > 1e-6:\n",
    "    i += 1\n",
    "    valueFunc2 = tempFunc\n",
    "    tempFunc = valueFuncIteration(valueFunc2)\n",
    "print('Convergence in {} steps'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d8e7389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    0.        ,  100.70100671,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,  102.37528774,  101.52366974,\n",
       "          0.        ,    0.        ,  109.48994702,  110.40904399,\n",
       "        111.33585617,    0.        ,    0.        ,  103.23464549,\n",
       "          0.        ,  106.77828428,  107.67464177,  108.57850104,\n",
       "          0.        ,  112.27044834,    0.        ,    0.        ,\n",
       "        104.10123282,  104.97509502,  105.888554  ,    0.        ,\n",
       "          0.        ,  114.16323441,  113.2128858 ,    0.        ,\n",
       "          0.        ,    0.        ,  103.78142811,    0.        ,\n",
       "          0.        ,    0.        ,  115.12156059,    0.        ,\n",
       "          0.        ,    0.        , -133.33332942,   90.98540012,\n",
       "       -133.33332942,    0.        , -133.33332942,  116.08793128,\n",
       "        122.02491563,    0.        ,    0.        ,   81.39949978,\n",
       "         93.67166194,   95.17286168,  108.34262248,  109.58365233,\n",
       "        123.64307016,  123.18224068,    0.        ,    0.        ,\n",
       "       -133.33332942,   81.39949978, -133.33332942,    0.        ,\n",
       "       -133.33332942,  125.24978753,  124.20738551,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,  133.33332942,    0.        ,\n",
       "          0.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueFunc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71e77bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_map = {0: 'Left', 1: 'Up', 2: 'Right', 3: 'Down'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30a7ac2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 3 | Action: Right | Policy Iteration Value: 100.7010102002196 | Value Iteration Value: 100.70100670774\n",
      "State: 11 | Action: Right | Policy Iteration Value: 102.37529123178209 | Value Iteration Value: 102.3752877393026\n",
      "State: 12 | Action: Up | Policy Iteration Value: 101.52367322965442 | Value Iteration Value: 101.52366973717493\n",
      "State: 15 | Action: Down | Policy Iteration Value: 109.48995051690076 | Value Iteration Value: 109.48994702413327\n",
      "State: 16 | Action: Down | Policy Iteration Value: 110.40904747912874 | Value Iteration Value: 110.40904398636131\n",
      "State: 17 | Action: Right | Policy Iteration Value: 111.33585966247094 | Value Iteration Value: 111.33585616970353\n",
      "State: 20 | Action: Right | Policy Iteration Value: 103.23464897839825 | Value Iteration Value: 103.23464548591886\n",
      "State: 22 | Action: Down | Policy Iteration Value: 106.7782877691457 | Value Iteration Value: 106.77828427637834\n",
      "State: 23 | Action: Down | Policy Iteration Value: 107.6746452597115 | Value Iteration Value: 107.67464176694396\n",
      "State: 24 | Action: Left | Policy Iteration Value: 108.57850453501321 | Value Iteration Value: 108.57850104224573\n",
      "State: 26 | Action: Right | Policy Iteration Value: 112.27045183161601 | Value Iteration Value: 112.2704483388487\n",
      "State: 29 | Action: Down | Policy Iteration Value: 104.10123631374762 | Value Iteration Value: 104.10123282126823\n",
      "State: 30 | Action: Down | Policy Iteration Value: 104.97509851098043 | Value Iteration Value: 104.97509501850112\n",
      "State: 31 | Action: Left | Policy Iteration Value: 105.88855749291497 | Value Iteration Value: 105.8885540001552\n",
      "State: 34 | Action: Right | Policy Iteration Value: 114.16323790726078 | Value Iteration Value: 114.16323441449354\n",
      "State: 35 | Action: Up | Policy Iteration Value: 113.21288929449881 | Value Iteration Value: 113.21288580173153\n",
      "State: 39 | Action: Left | Policy Iteration Value: 103.7814315891324 | Value Iteration Value: 103.78142810703108\n",
      "State: 43 | Action: Right | Policy Iteration Value: 115.1215640788626 | Value Iteration Value: 115.12156058609541\n",
      "State: 48 | Action: Left | Policy Iteration Value: 90.98540321957923 | Value Iteration Value: 90.985400121465\n",
      "State: 56 | Action: Down | Policy Iteration Value: 81.39950233342955 | Value Iteration Value: 81.3994997783592\n",
      "State: 57 | Action: Down | Policy Iteration Value: 93.67166484707683 | Value Iteration Value: 93.67166194260669\n",
      "State: 58 | Action: Down | Policy Iteration Value: 95.17286459965607 | Value Iteration Value: 95.1728616815331\n",
      "State: 59 | Action: Down | Policy Iteration Value: 108.34262576285258 | Value Iteration Value: 108.34262247533641\n",
      "State: 60 | Action: Down | Policy Iteration Value: 109.58365562763508 | Value Iteration Value: 109.58365233013537\n",
      "State: 61 | Action: Right | Policy Iteration Value: 123.64307385195802 | Value Iteration Value: 123.64307016465737\n",
      "State: 62 | Action: Right | Policy Iteration Value: 123.182244385098 | Value Iteration Value: 123.18224068296979\n",
      "State: 66 | Action: Left | Policy Iteration Value: 81.39950233342954 | Value Iteration Value: 81.3994997783592\n",
      "State: 70 | Action: Right | Policy Iteration Value: 125.24979123468198 | Value Iteration Value: 125.24978753198937\n",
      "State: 71 | Action: Up | Policy Iteration Value: 124.20738921318804 | Value Iteration Value: 124.2073855105102\n"
     ]
    }
   ],
   "source": [
    "for pi in range(policy.shape[0]):\n",
    "    if pi in valid_states:\n",
    "        print(\"\"\"State: {} | Action: {} | Policy Iteration Value: {} | Value Iteration Value: {}\"\"\".format(pi + 1, \n",
    "                                                                                                       action_map[opt_policy[pi]], \n",
    "                                                                                                       valueFunc[pi], \n",
    "                                                                                                       valueFunc2[pi]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a453b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse258",
   "language": "python",
   "name": "cse258"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
